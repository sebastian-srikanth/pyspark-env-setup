{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Read the csv file employee.csv with the below schema as a dataframe where all columns can have null values. Print the dataframe, it's schema and write it as a parquet file.\n",
    "ID (int)\n",
    "Name (str)\n",
    "HomeTown (str)\n",
    "Salary (double)\n",
    "JoiningDate (date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start Jupyter in the environment 'Python 3.6.8 64-bit (/usr/bin/python3)'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Pyspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"test_spark\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start Jupyter in the environment 'Python 3.6.8 64-bit (/usr/bin/python3)'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('employee.csv',header = True, inferSchema=True)\n",
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load('employee.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('employee.parquet')\n",
    "df.write.partitionBy(\"Name\").mode(\"overwrite\").parquet('employee.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Read the parquet part files from the above solution as a dataframe and add a new column JoiningDate_AsString by casting the column JoiningDate as str and write it as a csv file. Print the dataframe and it's schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('employee.parquet').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.parquet('employee.parquet/*').show() # if partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.parquet('employee.parquet/Name=Arpit').show() #for reading only one partition\n",
    "#column name will not be present in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcol_df = df.withColumn('JoiningDate_ASstring',df[\"JoiningDate\"].cast('String'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcol_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Read the csv file from the above solution and compare the columns 'JoiningDate' and 'JoiningDate_AsString'. For the records which are True, add a new column 'State' and fill the values as 'Karnataka' if the 'HomeTown' is in Karnataka state, else fill the values as 'Out of State'. Print the dataframe and it's schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "city_list = newcol_df.select(\"HomeTown\").distinct().collect()\n",
    "mylist = [r.HomeTown for r in city_list]\n",
    "compare_df = newcol_df.withColumn(\"state\",\n",
    "                            f.when( (f.col(\"JoiningDate_ASstring\") == f.col(\"JoiningDate\")) \n",
    "                                   &  (f.col('HomeTown') == 'Bengaluru'), 'Karnataka').otherwise('Other state')\n",
    "                        )\n",
    "compare_df.show()\n",
    "compare_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Create employee and department tables by reading the csv files employee.csv and department.csv respectively.\n",
    "#### (i) Find the total number of employees in each department with the department's average salary.\n",
    "#### (ii) Find the employees who have / had been idle for more than 30 days (who have / had not been allocated to any project) in Data Engineering department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>HomeTown</th>\n",
       "      <th>Salary</th>\n",
       "      <th>JoiningDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Arpit</td>\n",
       "      <td>Burhanpur</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2018-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Benu</td>\n",
       "      <td>Bhubaneswar</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2018-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Dilsher</td>\n",
       "      <td>Amritsar</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2018-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kiran</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2018-11-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     Name     HomeTown    Salary JoiningDate\n",
       "0   1    Arpit    Burhanpur   50000.0  2018-11-14\n",
       "1   2     Benu  Bhubaneswar  100000.0  2018-11-19\n",
       "2   3  Dilsher     Amritsar  100000.0  2018-11-19\n",
       "3   4    Kiran    Bengaluru   50000.0  2018-11-15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code\n",
    "employee_df = pd.read_csv(\"employee.csv\")\n",
    "dept_df = pd.read_csv('department.csv')\n",
    "employee_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>DepartmentName</th>\n",
       "      <th>Client</th>\n",
       "      <th>OnboardedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Engineering</td>\n",
       "      <td>Funding Circle</td>\n",
       "      <td>2019-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Engineering</td>\n",
       "      <td>Funding Circle</td>\n",
       "      <td>2018-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>Funding Circle</td>\n",
       "      <td>2018-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>Funding Circle</td>\n",
       "      <td>2018-12-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeID    DepartmentName          Client OnboardedDate\n",
       "0           1  Data Engineering  Funding Circle    2019-01-15\n",
       "1           2  Data Engineering  Funding Circle    2018-11-19\n",
       "2           3    Data Analytics  Funding Circle    2018-11-19\n",
       "3           4    Data Analytics  Funding Circle    2018-12-16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Write a function which accepts a dict and returns a validated dict. Below are the respective validations.\n",
    "#### (i) Validate the type of each key and raise TypeError if validation fails\n",
    "#### (ii) Validate if the key given in input dict is a new / unidentified key and raise KeyError if validation fails\n",
    "\n",
    "    sample_input1 = {\n",
    "        \"job_run_id\": \"dummy_job_run_id\",\n",
    "        \"job_name\": \"dummy_job_name\",\n",
    "        \"impacted_records_count\": 1000,\n",
    "        \"valid_records_count\": 950,\n",
    "        \"invalid_records_count\": 50,\n",
    "        \"comments\": \"dummy_comments\"\n",
    "    }\n",
    "\n",
    "    expected_output1 = {\n",
    "        \"job_run_id\": \"dummy_job_run_id\",\n",
    "        \"job_name\": \"dummy_job_name\",\n",
    "        \"impacted_records_count\": 1000,\n",
    "        \"valid_records_count\": 950,\n",
    "        \"invalid_records_count\": 50,\n",
    "        \"comments\": \"dummy_comments\"\n",
    "    }\n",
    "    \n",
    "    sample_input2 = {\n",
    "        \"job_run_id\": \"dummy_job_run_id\",\n",
    "        \"job_name\": \"dummy_job_name\",\n",
    "        \"impacted_records_count\": 1000,\n",
    "        \"valid_records_count\": 1000,\n",
    "        \"invalid_records_count\": \"zero\",\n",
    "        \"comments\": \"dummy_comments\"\n",
    "    }\n",
    "    \n",
    "    expected_output2 = TypeError: Incorrect data type for metric invalid_records_count\n",
    "\n",
    "    sample_input3 = {\n",
    "        \"job_run_id\": \"dummy_job_run_id\",\n",
    "        \"job_name\": \"dummy_job_name\",\n",
    "        \"impacted_records_count\": 1000,\n",
    "        \"valid_records_count\": 1000,\n",
    "        \"invalid_records_count\": 0,\n",
    "        \"comments\": \"dummy_comments\",\n",
    "        \"some_new_key\": \"some_value\"\n",
    "    }\n",
    "    \n",
    "    expected_output3 = KeyError: New / Unidentified metric some_new_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "sample_input1 = {\n",
    "    \"job_run_id\": \"dummy_job_run_id\",\n",
    "    \"job_name\": \"dummy_job_name\",\n",
    "    \"impacted_records_count\": 1000,\n",
    "    \"valid_records_count\": 950,\n",
    "    \"invalid_records_count\": 50,\n",
    "    \"comments\": \"dummy_comments\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_func(key,value):\n",
    "    sample_input1 = {\n",
    "    \"job_run_id\": str,\n",
    "    \"job_name\": str,\n",
    "    \"impacted_records_count\": int,\n",
    "    \"valid_records_count\": int,\n",
    "    \"invalid_records_count\": int,\n",
    "    \"comments\": str\n",
    "    }\n",
    "    \n",
    "    if key not in sample_input1:\n",
    "        print(\"KeyError: New / Unidentified metric {}\".format(key))\n",
    "    \n",
    "    if key in sample_input1 and isinstance(value,sample_input1[key]) == False:\n",
    "        print(\"TypeError: Incorrect data type for metric {}\".format(key))\n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input2 = {\n",
    "    \"job_run_id\": \"dummy_job_run_id\",\n",
    "    \"job_name\": \"dummy_job_name\",\n",
    "    \"impacted_records_count\": 1000,\n",
    "    \"valid_records_count\": 1000,\n",
    "    \"invalid_records_count\": \"zero\",\n",
    "    \"comments\": \"dummy_comments\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError: Incorrect data type for metric invalid_records_count\n"
     ]
    }
   ],
   "source": [
    "for key,value in sample_input2.items():\n",
    "    validate_func(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input3 = {\n",
    "    \"job_run_id\": \"dummy_job_run_id\",\n",
    "    \"job_name\": \"dummy_job_name\",\n",
    "    \"impacted_records_count\": 1000,\n",
    "    \"valid_records_count\": 1000,\n",
    "    \"invalid_records_count\": 0,\n",
    "    \"comments\": \"dummy_comments\",\n",
    "    \"some_new_key\": \"some_value\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError: New / Unidentified metric some_new_key\n"
     ]
    }
   ],
   "source": [
    "for key,value in sample_input3.items():\n",
    "    validate_func(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Consider a humongous list with millions of elements. Write a function to find the cumulative sum of every 5 elements. \n",
    "#### There can be some elements which might not be of int type, the function will need to gracefully handle the exceptions and pass to the next element. Function is supposed to return a list where every element is expected to be the cumulative sum of every 5 elements in input list.\n",
    "\n",
    "    sample_input = [50, 30, 20, 0, \"catch_me\", 0, \"you_got_me\", \"did_you_really_catch\", 40, 50, \"20\", 0, 0, 0, 10]\n",
    "    expected_output = [100, 190, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = [50, 30, 20, 0, \"catch_me\", 0, \"you_got_me\", \"did_you_really_catch\", 40, 50, \"20\", 0, 0, 0, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [i for i in sample_input if isinstance(i,int) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 30, 20, 0, 0, 40, 50, 0, 0, 0, 10]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 190, 200]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "cumsum = 0\n",
    "for i in range(0, len(filtered), 5):\n",
    "    cumsum += sum(filtered[i:i + 5])\n",
    "    result.append(cumsum)\n",
    "\n",
    "print(result) # [100, 190, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 6, 12, 18]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code\n",
    "list(range(0,20,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Write a function to print second highest frequency element in the list.\n",
    "\n",
    "    sample_input = [50, 30, 20, 0, \"catch_me\", 0, \"you_got_me\", \"did_you_really_catch\", 40, 50, \"20\", 0, 0, 0, 10]\n",
    "    expected_output = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "mydict = {}\n",
    "for elem in sample_input:\n",
    "    if elem in mydict:\n",
    "        mydict[elem] +=1\n",
    "    else:\n",
    "        mydict[elem] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50: 1,\n",
       " 30: 0,\n",
       " 20: 0,\n",
       " 0: 4,\n",
       " 'catch_me': 0,\n",
       " 'you_got_me': 0,\n",
       " 'did_you_really_catch': 0,\n",
       " 40: 0,\n",
       " '20': 0,\n",
       " 10: 0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second = sorted(list(mydict.values()))[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "for i,v in mydict.items():\n",
    "    if v == second:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Write a function which accepts a string and returns a string with the cases swaped. Do not use the built-in packages / methods like swapcase, etc to swap cases. Implement your own logic. Please try to use list comprehensions if possible.\n",
    "\n",
    "    sample_input = \"You're aweSOME !!!\"\n",
    "    expected_output = \"yOU'RE AWEsome !!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hELLO mY nAME iS peter\n"
     ]
    }
   ],
   "source": [
    "txt = \"Hello My Name Is PETER\"\n",
    "\n",
    "x = txt.swapcase()\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. Write a simple function and decorate its behavior using python decorators. Also, write test cases for the function by mocking / patching the decorator's functionalitites and setting its respective return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. Write a test function for the below code snippet.\n",
    "\n",
    "    def sample_func(a):\n",
    "        result = []\n",
    "        if a == 0:\n",
    "            raise ValueError(\"0 cannot be given as an input value. Divide by zero exception.\")\n",
    "        else:\n",
    "            for i in range(1, a+1):\n",
    "                result.append([i+i, i-i, i*i, i/i])\n",
    "        return result\n",
    "        \n",
    "#### (i) Assert the positive cases\n",
    "#### (ii) Assert the negative cases\n",
    "#### (iii) Assert the functions's response type\n",
    "#### (iv) Assert the exceptions raised        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
